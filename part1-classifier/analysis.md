# Анализ сложных случаев и улучшения промпта

## Какие ошибки ловить сложнее всего

### 1. **Косвенное подтверждение неверного ответа**
**Проблема**: ИИ не делает вычисление сам, но соглашается с неверным ответом ученика через перефразирование или продолжение логики.

**Пример**:
```
Ученик: "Я получил 75 для площади круга радиусом 5"
ИИ: "Отлично! Теперь используй это значение для следующего шага"
```

**Сложность**: Непонятно, является ли это ошибкой ИИ (не заметил неверное значение) или это педагогическая тактика (дать ученику продолжить и найти ошибку позже).

---

### 2. **Опечатки в числах vs реальные ошибки**
**Проблема**: Отличить случайную опечатку от математической ошибки.

**Пример**:
```
ИИ: "S = πr² = 3.14 × 25 = 78.9" (вместо 78.5)
```

**Сложность**: Это может быть округление, опечатка или реальная вычислительная ошибка. Нужен более строгий контекст.

---

### 3. **Педагогические упрощения vs ошибки**
**Проблема**: ИИ может давать упрощенные объяснения для начинающих, которые технически неточны.

**Пример**:
```
ИИ: "Производная показывает скорость роста функции"
```
(технически неполное, но педагогически полезное упрощение)

**Сложность**: Граница между упрощением и ошибкой размыта.

---

### 4. **Цепочка рассуждений с ошибкой в середине**
**Проблема**: ИИ делает длинное решение, где ошибка скрыта в середине последовательности шагов.

**Пример**:
```
ИИ: "Сначала найдем производную: f'(x) = 2x. Затем f'(3) = 6.
     Теперь используем формулу касательной: y = 6x + 5.
     Подставим x=0: y = 5"
```
(ошибка в формуле касательной)

**Сложность**: Модель должна тщательно проверять каждый шаг, а не только итоговый результат.

---

### 5. **Неявные математические утверждения**
**Проблема**: ИИ делает неверное математическое утверждение, но не явно, а через логику решения.

**Пример**:
```
ИИ: "Если a > b и c > d, то a + c > b + d и a × c > b × d"
```
(второе утверждение неверно для отрицательных чисел)

**Сложность**: Требуется глубокое понимание математики и проверка всех граничных случаев.

---

## Как бы я улучшил промпт

### 1. **Chain-of-Thought анализ**
Добавить требование разбивать проверку на шаги:
```
1. Определи, делал ли ИИ СОБСТВЕННЫЕ вычисления
2. Если да — проверь их корректность
3. Если нет — проверь, не утверждает ли он неверные факты
4. Вынеси финальное решение
```

### 2. **Few-Shot примеры прямо в промпте**
Добавить 10-15 реальных аннотированных примеров из датасета для калибровки модели:
- Граничные случаи (опечатки, упрощения, косвенные подтверждения)
- Четкие примеры ошибок и не-ошибок

### 3. **Математическая верификация**
Добавить шаг явной проверки вычислений:
```
Если ИИ делал вычисления:
- Извлеки математическое выражение
- Проверь его корректность пошагово
- Сравни с правильным результатом
```

### 4. **Градация уверенности**
Вместо бинарной классификации (0/1) использовать:
- 0: точно нет ошибки
- 0.5: неясный случай (требуется человеческая проверка)
- 1: точно есть ошибка

Это помогло бы выявлять сложные граничные случаи.

### 5. **Контекстная память**
Добавить анализ всей истории диалога, а не только последней реплики:
```
Проверь:
- Противоречит ли текущий ответ ИИ предыдущим его ответам?
- Повторяет ли ИИ ошибку из истории или вносит новую?
```

### 6. **Специализированные проверки**
Для разных типов математических ошибок использовать специфичные правила:

- **Вычислительные**: проверять порядок величин (78.5 vs 7850)
- **Формулы**: сверять с базой корректных формул
- **Логические**: проверять логические связки (если...то)
- **Определения**: сверять с математическим глоссарием

### 7. **Мета-промпт для калибровки**
Добавить:
```
Если ты сомневаешься в оценке — объясни почему и поставь confidence_score
Лучше ложно положительное (пометить ошибку), чем пропустить реальную ошибку
```

### 8. **A/B тестирование формулировок**
Протестировать разные формулировки критериев:
- "ИИ сам выполняет вычисление" vs "ИИ является автором вычисления"
- "неверное" vs "некорректное" vs "ошибочное"

### 9. **Использование Code Interpreter**
Для численных проверок:
```
Если в ответе есть вычисления — запусти их в Python для верификации
Сравни результат ИИ с точным вычислением
```

### 10. **Обратная связь от аннотаторов**
Собирать случаи, где промпт ошибся:
- Ложные срабатывания (FP)
- Пропущенные ошибки (FN)
- Добавлять их в few-shot примеры для непрерывного улучшения

---

## Оценка текущей версии промпта

### Сильные стороны:
✓ Четкие критерии разделения ошибок/не-ошибок
✓ Примеры для калибровки
✓ Структурированный JSON-выход
✓ Учет контекста истории диалога

### Слабые стороны:
✗ Нет пошаговой проверки
✗ Нет градации уверенности
✗ Ограниченное количество примеров
✗ Нет специализированных правил для типов ошибок

### Ожидаемая точность:
- **Accuracy**: 75-85% (простые случаи)
- **Recall**: 70-80% (может пропустить тонкие ошибки)
- **Precision**: 80-90% (ложных срабатываний должно быть меньше)

---

## План дальнейшего развития

1. **Короткий срок (1 день)**:
   - Добавить больше few-shot примеров
   - Протестировать на валидационной выборке
   - Добавить confidence_score

2. **Средний срок (1 неделя)**:
   - Реализовать Chain-of-Thought анализ
   - Добавить математическую верификацию через Code Interpreter
   - Собрать обратную связь от аннотаторов

3. **Долгий срок (1 месяц)**:
   - Fine-tuning модели на размеченных данных
   - Ансамбль из нескольких промптов/моделей
   - Интеграция с базой математических знаний
